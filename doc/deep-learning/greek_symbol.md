# 📖 神经网络常见希腊字母

## 目录
| 字母 | 中文名 | 常见用途 |
|------|-------|--------|
| α | 阿尔法 | 学习率、正则化系数 |
| β | 贝塔 | 动量参数、统计系数 |
| γ | 伽马 | 学习率调整、归一化参数 |
| σ | 西格玛 | Sigmoid 激活函数 |
| θ | 西塔 | 模型参数 |
| η | 伊塔 | 学习率 |
| Δ | 德尔塔 | 权重更新、误差 |

---

## α (Alpha)
**读法**：阿尔法 (alpha)

**常见含义**：学习率（有时用来替代 $\eta$）、正则化系数、动量参数。

---

## β (Beta)
**读法**：贝塔 (beta)

**常见含义**：在优化算法中表示动量参数；在统计学中表示系数或偏差。

---

## γ (Gamma)
**读法**：伽马 (gamma)

**常见含义**：学习率调整因子；在 Batch Normalization 中表示缩放参数。

---

## σ (Sigma)
**读法**：西格玛 (sigma)

**常见含义**：Sigmoid 激活函数

**公式**：

$$\sigma(z) = \frac{1}{1 + e^{-z}}$$

**性质**：输出范围在 $(0,1)$，常用于概率解释和二分类问题。

---

## θ (Theta)
**读法**：西塔 (theta)

**常见含义**：模型参数的统称（权重和偏置），尤其在机器学习公式中常用。

**符号**：$\theta = \{W, b\}$，表示所有可学习的参数。

---

## η (Eta)
**读法**：伊塔 (eta)

**常见含义**：学习率 (learning rate)，控制梯度下降更新步长。

**更新公式**：

$$\theta_{t+1} = \theta_t - \eta \nabla J(\theta_t)$$

其中 $\eta$ 决定了每次迭代的步长大小。

---

## Δ (Delta)
**读法**：德尔塔 (delta)

**常见含义**：变化量或差值，在神经网络中常表示误差或权重更新量。

**应用**：
- 误差项：$\delta_l = \frac{\partial J}{\partial z^l}$（反向传播中的梯度）
- 权重更新：$\Delta W = -\eta \frac{\partial J}{\partial W}$